Absolutely! Here’s the full `README.md` ready for copy-paste:

---

```markdown
# 🛰️ NASA Asteroids API – Automated Test Suite

This project contains an automated API test suite for validating the [NASA JPL Asteroids NeoWS API](https://api.nasa.gov/) using Python, Pytest, and Docker. It includes CI/CD integration with GitHub Actions, rich HTML and JUnit reports, log artifacts, and support for regression, smoke, and other targeted test types.

---

## 🚀 Tech Stack

- **Python 3.10**
- **Pytest** with custom markers
- **Docker** for test environment isolation
- **GitHub Actions** CI/CD
- **Reports**:
  - HTML report via `pytest-html`
  - JUnit XML for GitHub UI integration
  - Test logs with timestamps
- **Test Types Supported**:  
  `smoke`, `regression`, `validation`, `negative`, `edgecase`, `filtering`, `performance`

---

## 📂 Project Structure

```
.
├── modules
│   └── backend_tests
│       ├── controllers/          # API logic & service layer
│       ├── general/              # Request builders
│       ├── helpers/              # Data & threading utilities
│       └── tests/                # Test cases
│           ├── test_asteroids_api.py
│           └── test_data.py
├── output/                      # Logs (autogenerated)
├── reports/                     # HTML + JUnit reports
├── Dockerfile
├── docker-compose.yml
├── pytest.ini
└── requirements.txt
```

---

## 🧪 How to Run Tests

### Option 1: 🐳 Docker (recommended)

```bash
docker build --build-arg TEST_TYPE=regression -t asteroids-api-tests .

docker run --rm \
  -e TEST_TYPE=regression \
  -v $(pwd)/reports:/app/reports \
  -v $(pwd)/output:/app/output \
  asteroids-api-tests
```

### Option 2: 🧪 Local (dev use only)

```bash
pip install -r requirements.txt

pytest -m regression \
  --html=reports/report.html \
  --junitxml=reports/junit.xml
```

---

## 📦 Test Reports & Artifacts

| File                       | Description                              |
|----------------------------|------------------------------------------|
| `reports/report.html`      | Full visual test report                  |
| `reports/junit.xml`        | GitHub Actions UI integration            |
| `output/*.log`             | Detailed test + Docker logs (timestamped)|

---

## ⚙️ GitHub Actions – CI/CD

### ✅ Triggered By:

- Push to `main`
- Pull request to `main`
- Manual trigger (with marker + branch)
- Nightly run at 00:00 UTC

### 🎯 What It Does:

- Builds and runs tests in Docker
- Accepts dynamic markers like `regression`, `smoke`, etc.
- Uploads:
  - ✅ Test summary to GitHub UI
  - 📎 HTML + JUnit reports
  - 📜 Log files from test run

---

## 🏷️ Pytest Markers

```ini
[pytest]
markers =
    smoke: Smoke tests suite to ensure API works as expected
    regression: Tests that run in every regression/nightly cycle
    flaky_regression: Rerun flaky tests 3 times
    negative: Invalid inputs and unexpected API behavior
    edgecase: Outlier conditions like extreme future dates
    validation: Field format and type checking
    filtering: Query param filters like distance or date
    performance: Simulated high-load scenarios
```

---

## 📈 GitHub Actions Test Summary

- ☑️ Integrated into UI via `junit.xml`
- 🧪 Summary shows test results (pass/fail/skip)
- 📁 All logs and reports are attached as downloadable artifacts

---
